{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore for possible warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# necessary packages\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# additional certain short functions\n",
    "from torch import is_tensor\n",
    "from matplotlib.pyplot import pause\n",
    "from random import randint\n",
    "from copy import deepcopy\n",
    "from math import floor, ceil\n",
    "from torch import stack\n",
    "from torch import cat\n",
    "\n",
    "# packages for data export and import\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training dataset\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# get testing dataset\n",
    "testing_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# class names\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "# # print random item to visualize\n",
    "# rand = random.randint(0, 59999)\n",
    "# img = training_data.data[rand]\n",
    "# plt.imshow(img, cmap='gray')\n",
    "# print(\"ground truth = \", training_data.classes[training_data.targets[rand]])\n",
    "\n",
    "# # print dataset size \n",
    "# size = len(training_data)\n",
    "# print(\"Dataset size = \", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expansion shape = torch.Size([4, 84, 112])\n",
      "temp shape = torch.Size([70, 84, 112])\n",
      "numbers of each original album = [22, 13, 22, 13]\n",
      "score shape = torch.Size([82, 84, 112])\n",
      "numbers of each final album = [25, 15, 26, 16]\n",
      "length of number_lsit = 4\n",
      "sum of first 2 elements in number_list = 40\n",
      "stride_list = [4, 7, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "from data_generate import *\n",
    "\n",
    "dataset = training_data\n",
    "name = [\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "number = 1\n",
    "\n",
    "test = pick(dataset, name, number)\n",
    "test, number_list, stride_list = album(test, is_rand_stride = True, is_rand_pos = True)\n",
    "\n",
    "print(\"length of number_lsit =\", len(number_list))\n",
    "print(\"sum of first 2 elements in number_list =\", sum(number_list[:2]))\n",
    "print(\"stride_list =\", stride_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([78, 1])\n",
      "(84, 112)\n"
     ]
    }
   ],
   "source": [
    "from data_io import *\n",
    "\n",
    "data = dif_frame(test, number_list)\n",
    "data_gt = vector(number_list, stride_list)\n",
    "\n",
    "# print(data.shape)\n",
    "# print(data_gt.shape)\n",
    "\n",
    "# CSV_NAME = 'sample.csv'\n",
    "# IMAGE_NAME = 'sample'\n",
    "\n",
    "# gt_export(data_gt, CSV_NAME)\n",
    "# gt = gt_import(CSV_NAME)\n",
    "# image_export(data, IMAGE_NAME)\n",
    "\n",
    "\n",
    "# testing path\n",
    "PATH_DATA = os.path.join(os.getcwd(), \"data\\\\test\")\n",
    "\n",
    "# export data testing\n",
    "CSV_NAME = \"samlpe.csv\"\n",
    "isExist = os.path.exists(PATH_DATA)\n",
    "if not isExist:\n",
    "    os.mkdir(PATH_DATA)\n",
    "pd.DataFrame(data_gt).to_csv(os.path.join(PATH_DATA, CSV_NAME), index_label = \"Ground Truth\", header = ['x-vector'])\n",
    "\n",
    "# import data testing\n",
    "df = pd.read_csv(os.path.join(PATH_DATA, CSV_NAME))\n",
    "gt = torch.Tensor(df.values[:, 1:]).reshape(len(df), 1)\n",
    "print(gt.shape)\n",
    "\n",
    "# export image testing\n",
    "IMAGE_NAME = \"samlpe.png\"\n",
    "array = data[2].numpy().astype(np.uint8)    # np.uint8 before Image.fromarray\n",
    "im = Image.fromarray(array)\n",
    "im.save(os.path.join(PATH_DATA, IMAGE_NAME), format=\"png\")\n",
    "\n",
    "# import image testing\n",
    "img = Image.open(os.path.join(PATH_DATA, IMAGE_NAME))\n",
    "print(np.array(list(img.getdata())).reshape(28*3, 28*4).shape)\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view image\n",
    "for i in range(len(data)):\n",
    "    plt.imshow(data[i], cmap='gray')\n",
    "    pause(0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('auto_labeling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec129e0590d45a22483b850cd1c473456f2c02a48b73be1599d608a53736fee7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

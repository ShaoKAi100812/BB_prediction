{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion-MNIST-based simulated production line prediction\n",
    "<font color=#FF0000>Description, TO BE DONE!!</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary packages\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# additional certain short functions\n",
    "from torch import is_tensor\n",
    "from matplotlib.pyplot import pause\n",
    "from random import randint\n",
    "from copy import deepcopy\n",
    "from math import floor, ceil\n",
    "from torch import stack\n",
    "from torch import cat\n",
    "\n",
    "# import custom functions\n",
    "from data_generate import *\n",
    "from data_io import *\n",
    "from CNN import *\n",
    "from FCN import *\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# apply CUDA\n",
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize dataset\n",
    "class ProductLineDataset(Dataset):\n",
    "    def __init__(self, image: torch.Tensor, gt: torch.Tensor):\n",
    "        self.x = image.reshape(len(image), 1, 28*3, 28*4).type(torch.float32)\n",
    "        self.y = gt.type(torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define file names\n",
    "CSV_NAME_TRAIN_02346 = 'train_02346.csv'\n",
    "CSV_NAME_TEST_02346 = 'test_02346.csv'\n",
    "CSV_NAME_TEST_579 = 'test_579.csv'\n",
    "CSV_NAME_TEST_18 = 'test_18.csv'\n",
    "IMAGE_NAME_TRAIN_02346 = 'train_02346'\n",
    "IMAGE_NAME_TEST_02346 = 'test_02346'\n",
    "IMAGE_NAME_TEST_579 = 'test_579'\n",
    "IMAGE_NAME_TEST_18 = 'test_18'\n",
    "\n",
    "# import data\n",
    "# 1-D ground truth\n",
    "gt_train_02346 = gt_import(CSV_NAME_TRAIN_02346)\n",
    "gt_test_02346 = gt_import(CSV_NAME_TEST_02346)\n",
    "gt_test_579 = gt_import(CSV_NAME_TEST_579)\n",
    "gt_test_18 = gt_import(CSV_NAME_TEST_18)\n",
    "\n",
    "# 2-D ground truth\n",
    "gt_train_02346 = torch.cat((gt_train_02346.reshape(len(gt_train_02346), 1), torch.zeros(len(gt_train_02346), 1)), dim = 1)\n",
    "gt_test_02346 = torch.cat((gt_test_02346.reshape(len(gt_test_02346), 1), torch.zeros(len(gt_test_02346), 1)), dim = 1)\n",
    "gt_test_579 = torch.cat((gt_test_579.reshape(len(gt_test_579), 1), torch.zeros(len(gt_test_579), 1)), dim = 1)\n",
    "gt_test_18 = torch.cat((gt_test_18.reshape(len(gt_test_18), 1), torch.zeros(len(gt_test_18), 1)), dim = 1)\n",
    "\n",
    "# 4-D image data\n",
    "image_train_02346 = image_import(gt_train_02346, IMAGE_NAME_TRAIN_02346)/255.\n",
    "image_test_02346 = image_import(gt_test_02346, IMAGE_NAME_TEST_02346)/255.\n",
    "image_test_579 = image_import(gt_test_579, IMAGE_NAME_TEST_579)/255.\n",
    "image_test_18 = image_import(gt_test_18, IMAGE_NAME_TEST_18)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10415, 2])\n",
      "torch.Size([10415, 1, 84, 112])\n"
     ]
    }
   ],
   "source": [
    "# print shapes\n",
    "print(gt_train_02346.shape)\n",
    "print(image_train_02346.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "dataset_train_02346 = ProductLineDataset(image_train_02346, gt_train_02346)\n",
    "dataset_test_02346 = ProductLineDataset(image_test_02346, gt_test_02346)\n",
    "dataset_test_579 = ProductLineDataset(image_test_579, gt_test_579)\n",
    "dataset_test_18 = ProductLineDataset(image_test_18, gt_test_18)\n",
    "\n",
    "# define dataloader\n",
    "dataloader_train_02346 = DataLoader(dataset_train_02346, batch_size=64, shuffle=True)\n",
    "dataloader_test_02346 = DataLoader(dataset_test_02346, batch_size=1, shuffle=True)  # batch_size=1 for test\n",
    "dataloader_test_579 = DataLoader(dataset_test_579, batch_size=1, shuffle=True)\n",
    "dataloader_test_18 = DataLoader(dataset_test_18, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 84, 112])\n",
      "Shape of y:  torch.Size([64, 2])\n",
      "Data type of y:  torch.float32\n",
      "tensor([[4., 0.],\n",
      "        [5., 0.],\n",
      "        [3., 0.],\n",
      "        [3., 0.],\n",
      "        [3., 0.],\n",
      "        [6., 0.],\n",
      "        [3., 0.],\n",
      "        [3., 0.],\n",
      "        [5., 0.],\n",
      "        [7., 0.],\n",
      "        [3., 0.],\n",
      "        [3., 0.],\n",
      "        [7., 0.],\n",
      "        [7., 0.],\n",
      "        [3., 0.],\n",
      "        [5., 0.],\n",
      "        [5., 0.],\n",
      "        [6., 0.],\n",
      "        [3., 0.],\n",
      "        [5., 0.],\n",
      "        [3., 0.],\n",
      "        [5., 0.],\n",
      "        [5., 0.],\n",
      "        [5., 0.],\n",
      "        [7., 0.],\n",
      "        [4., 0.],\n",
      "        [6., 0.],\n",
      "        [4., 0.],\n",
      "        [3., 0.],\n",
      "        [4., 0.],\n",
      "        [3., 0.],\n",
      "        [3., 0.],\n",
      "        [3., 0.],\n",
      "        [4., 0.],\n",
      "        [5., 0.],\n",
      "        [3., 0.],\n",
      "        [5., 0.],\n",
      "        [7., 0.],\n",
      "        [3., 0.],\n",
      "        [7., 0.],\n",
      "        [4., 0.],\n",
      "        [4., 0.],\n",
      "        [4., 0.],\n",
      "        [4., 0.],\n",
      "        [4., 0.],\n",
      "        [4., 0.],\n",
      "        [4., 0.],\n",
      "        [6., 0.],\n",
      "        [6., 0.],\n",
      "        [7., 0.],\n",
      "        [7., 0.],\n",
      "        [5., 0.],\n",
      "        [5., 0.],\n",
      "        [3., 0.],\n",
      "        [4., 0.],\n",
      "        [7., 0.],\n",
      "        [5., 0.],\n",
      "        [4., 0.],\n",
      "        [4., 0.],\n",
      "        [3., 0.],\n",
      "        [7., 0.],\n",
      "        [4., 0.],\n",
      "        [3., 0.],\n",
      "        [7., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# visualize the shape\n",
    "for X, y in dataloader_train_02346:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape)\n",
    "    print(\"Data type of y: \", y.dtype)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions \n",
    "def train(model, dataloader, loss_fn, optimizer):   # put epoch in main better for loss calculation\n",
    "    # size of dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # set model mode\n",
    "    model.train()\n",
    "    \n",
    "    # train batches per epoch\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # move data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        score = model(X)\n",
    "        loss = loss_fn(score, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 40 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test(model, dataloader, loss_fn):\n",
    "    # size of dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # number of batches\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    # set model mode\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            # move data to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            score = model(X)\n",
    "            test_loss += loss_fn(score, y).item()\n",
    "            correct += 1 - abs(round(score[0][0].item()) - y[0][0].item()) / y[0][0].item()    # only for batch_size=1\n",
    "    \n",
    "    # calculate the average loss and accuracy\n",
    "    test_loss /= num_batches\n",
    "    correct /= num_batches\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN(\n",
      "  (fc1): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=9408, out_features=4096, bias=True)\n",
      "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc3): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (fc4): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (fc5): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (fc6): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_channel = (28*3)*(28*4)\n",
    "node_1 = 4096\n",
    "node_2 = 4096\n",
    "node_3 = 1024\n",
    "node_4 = 1024\n",
    "node_5 = 64\n",
    "node_6 = 64\n",
    "out_channel = 2\n",
    "\n",
    "FCN_model = FCN(in_channel, node_1, node_2, node_3, node_4, \\\n",
    "    node_5, node_6, out_channel).to(device=device)\n",
    "print(FCN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=1120, out_features=4096, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc3): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (fc4): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_channel = 1\n",
    "channel_1 = 16\n",
    "channel_2 = 16\n",
    "channel_3 = 8\n",
    "node_1 = 4096\n",
    "node_2 = 4096\n",
    "node_3 = 1024\n",
    "node_4 = 256\n",
    "out_channel = 2\n",
    "\n",
    "CNN_model = CNN(in_channel, channel_1, channel_2, channel_3, \\\n",
    "    node_1, node_2, node_3, node_4, out_channel).to(device=device)\n",
    "print(CNN_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup and train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# define lose function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# define optimizer\n",
    "optimizer_FCN = torch.optim.Adam(FCN_model.parameters(), lr=learning_rate)\n",
    "optimizer_CNN = torch.optim.Adam(CNN_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 12.348166  [    0/10415]\n",
      "loss: 1.323632  [ 2560/10415]\n",
      "loss: 0.798921  [ 5120/10415]\n",
      "loss: 1.025570  [ 7680/10415]\n",
      "loss: 0.734814  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.842968 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.974456  [    0/10415]\n",
      "loss: 0.664802  [ 2560/10415]\n",
      "loss: 0.546709  [ 5120/10415]\n",
      "loss: 0.793517  [ 7680/10415]\n",
      "loss: 0.688872  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.835731 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.697943  [    0/10415]\n",
      "loss: 0.768792  [ 2560/10415]\n",
      "loss: 0.679389  [ 5120/10415]\n",
      "loss: 0.853266  [ 7680/10415]\n",
      "loss: 0.438562  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 1.035536 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.628119  [    0/10415]\n",
      "loss: 0.587405  [ 2560/10415]\n",
      "loss: 0.888324  [ 5120/10415]\n",
      "loss: 0.647689  [ 7680/10415]\n",
      "loss: 0.525349  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 1.424564 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.695083  [    0/10415]\n",
      "loss: 0.752029  [ 2560/10415]\n",
      "loss: 0.544341  [ 5120/10415]\n",
      "loss: 0.598547  [ 7680/10415]\n",
      "loss: 0.631319  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 1.178568 \n",
      "\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "# set epoch\n",
    "epoch = 5\n",
    "\n",
    "# start training\n",
    "for t in range(epoch):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(FCN_model, dataloader_train_02346, loss_fn, optimizer_FCN)\n",
    "    test(FCN_model, dataloader_test_02346, loss_fn)\n",
    "print(\"Done!!\")\n",
    "\n",
    "# model saving\n",
    "torch.save(FCN_model.state_dict(), \"FCN.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 12.197427  [    0/10415]\n",
      "loss: 0.753928  [ 2560/10415]\n",
      "loss: 0.450393  [ 5120/10415]\n",
      "loss: 0.502307  [ 7680/10415]\n",
      "loss: 0.919433  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.528720 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.942880  [    0/10415]\n",
      "loss: 0.271870  [ 2560/10415]\n",
      "loss: 0.388227  [ 5120/10415]\n",
      "loss: 0.295006  [ 7680/10415]\n",
      "loss: 0.444954  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.740645 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.272083  [    0/10415]\n",
      "loss: 0.288768  [ 2560/10415]\n",
      "loss: 0.465035  [ 5120/10415]\n",
      "loss: 0.194897  [ 7680/10415]\n",
      "loss: 0.524283  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.339464 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.457470  [    0/10415]\n",
      "loss: 0.703181  [ 2560/10415]\n",
      "loss: 0.366486  [ 5120/10415]\n",
      "loss: 0.314253  [ 7680/10415]\n",
      "loss: 0.233102  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 1.469990 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.592376  [    0/10415]\n",
      "loss: 0.209161  [ 2560/10415]\n",
      "loss: 0.417707  [ 5120/10415]\n",
      "loss: 0.354388  [ 7680/10415]\n",
      "loss: 0.305763  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.345524 \n",
      "\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "# set epoch\n",
    "epoch = 5\n",
    "\n",
    "# start training\n",
    "for t in range(epoch):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(CNN_model, dataloader_train_02346, loss_fn, optimizer_CNN)\n",
    "    test(CNN_model, dataloader_test_02346, loss_fn)\n",
    "print(\"Done!!\")\n",
    "\n",
    "# model saving\n",
    "torch.save(CNN_model.state_dict(), \"CNN.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#FF0000>Visualization reference (non-used yet) <font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single bounding box testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box(col, row, box_x, box_y):    # position + length / width (visualization usage)\n",
    "    view = torch.zeros([28*3, 28*4], dtype=torch.float32)\n",
    "    # set the box, outside the target with one pixel\n",
    "    view[row-box_y:row+1, col-box_x] = 1\n",
    "    view[row-box_y:row+1, col] = 1\n",
    "    view[row-box_y, col-box_x:col+1] = 1\n",
    "    view[row, col-box_x:col+1] = 1\n",
    "    return view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import pause\n",
    "from random import randint\n",
    "from copy import deepcopy\n",
    "\n",
    "rand_x = randint(14, 27)\n",
    "rand_y = randint(27, 28*3-1)\n",
    "print(\"new start position [x, y] = [\", rand_x,\",\", rand_y, \"]\")\n",
    "\n",
    "rand_start = deepcopy(aug_sample)\n",
    "box_origin = box(27, 21, 27, 15)    # array for visualization, the only manual input part\n",
    "box_sample = deepcopy(box_origin)\n",
    "\n",
    "plt.imshow(rand_start, cmap='gray')\n",
    "plt.imshow(box_origin, cmap='gray', alpha=0.3)\n",
    "pause(0.1)\n",
    "\n",
    "# initial movement\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        rand_start[rand_y-i][rand_x-j] = rand_start[27-i][27-j]\n",
    "\n",
    "for i in range(29):\n",
    "    for j in range(29):\n",
    "        box_origin[rand_y-i+1][rand_x-j+1] = box_origin[28-i][28-j]\n",
    "\n",
    "# clean other part\n",
    "rand_start[:rand_y-28+1, :] = 0\n",
    "rand_start[:, rand_x+1:rand_x+28+1] = 0\n",
    "box_origin[:rand_y-28, :] = 0       # 1-pixel cleaning region difference\n",
    "box_origin[:, rand_x+1:rand_x+28+1] = 0\n",
    "\n",
    "plt.imshow(rand_start, cmap='gray')\n",
    "plt.imshow(box_origin, cmap='gray', alpha=0.3)\n",
    "pause(0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sequential bounding box visualization and random position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil\n",
    "from torch import cat\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import pause\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequential box preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "stride = 5\n",
    "first_frame = deepcopy(box_sample)\n",
    "next_frame = deepcopy(box_sample)\n",
    "y_box = deepcopy(box_sample)\n",
    "\n",
    "# show info\n",
    "print(y_box.size())\n",
    "plt.imshow(y_box, cmap='gray')\n",
    "pause(0.1)\n",
    "\n",
    "for i in range(floor((112-28)/stride)):\n",
    "   # moving part (1-dim only)\n",
    "   for j in range(30):  # bigger range to cover bounding box\n",
    "      next_frame[:, 30+stride*(i+1)-(j+1)] = next_frame[:, 30+stride*i-(j+1)]\n",
    "   next_frame[:, :stride*(i+1)] = 0  # clean other area\n",
    "   \n",
    "   # sequencing part\n",
    "   if i == 0:\n",
    "      y_box = stack((first_frame, next_frame)) \n",
    "   else:\n",
    "      y_box = cat((y_box, next_frame.reshape(1, 28*3, 28*4)), dim=0)\n",
    "      \n",
    "   # # show info\n",
    "   # print(y_box.size())\n",
    "   # plt.imshow(y_box[i+1], cmap='gray')\n",
    "   # pause(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parallel moving and concat last frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential data preparation\n",
    "y_box_moved = deepcopy(y_box)\n",
    "y_moved = deepcopy(y)\n",
    "rand_x = randint(14, 27)\n",
    "rand_y = randint(27, 28*3-1)\n",
    "print(\"new start position [x, y] = [\", rand_x,\",\", rand_y, \"]\")\n",
    "\n",
    "# # visualization for no parallel movement\n",
    "# for i in range(len(y_box_moved)):\n",
    "#     plt.imshow(y_moved[i], cmap='gray')\n",
    "#     plt.imshow(y_box_moved[i], cmap='gray', alpha=0.3)\n",
    "#     pause(0.1)\n",
    "\n",
    "# all frames move left parellel\n",
    "for i in range(floor((112-28)/stride)+1): \n",
    "    # moving items\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            y_moved[i][rand_y-j][rand_x+stride*i-k] = y_moved[i][27-j][27+stride*i-k]\n",
    "    # moving box\n",
    "    for j in range(29):\n",
    "        for k in range(29):\n",
    "            y_box_moved[i][rand_y-j+1][rand_x+stride*i-k+1] = y_box_moved[i][28-j][28+stride*i-k]\n",
    "          \n",
    "    # clean other area\n",
    "    y_moved[i][:rand_y-28+1, :] = 0\n",
    "    y_moved[i][:, rand_x+stride*i+1:] = 0\n",
    "    y_box_moved[i][:rand_y-28+1, :] = 0\n",
    "    y_box_moved[i][:, rand_x+stride*i+1:] = 0\n",
    "   \n",
    "    # show info\n",
    "    plt.imshow(y_moved[i], cmap='gray')\n",
    "    plt.imshow(y_box_moved[i], cmap='gray', alpha=0.3)\n",
    "    pause(0.1)\n",
    "\n",
    "# initialization\n",
    "frame_old = len(y_moved)   # number of old frames\n",
    "next_frame = deepcopy(y_moved[frame_old-1])\n",
    "next_frame_box = deepcopy(y_box_moved[frame_old-1])\n",
    "\n",
    "# last frame moves right and cat\n",
    "for i in range(ceil((28-rand_x)/stride)+1):\n",
    "    # move next frame\n",
    "    for j in range(28):\n",
    "        if rand_x+stride*(frame_old+i)-j < 112:\n",
    "           next_frame[:, rand_x+stride*(frame_old+i)-j] = next_frame[:, rand_x+stride*(frame_old+i-1)-j]\n",
    "    for j in range(29):\n",
    "        if rand_x+stride*(frame_old+i)-j+1 < 112:\n",
    "           next_frame_box[:, rand_x+stride*(frame_old+i)-j+1] = next_frame_box[:, rand_x+stride*(frame_old+i-1)-j+1]\n",
    "    # clean and cat\n",
    "    next_frame[:, :rand_x+stride*(frame_old+i)-28+1] = 0\n",
    "    y_moved = cat((y_moved, next_frame.reshape(1, 28*3, 28*4)), dim=0)\n",
    "    next_frame_box[:, :rand_x+stride*(frame_old+i)-28+1] = 0\n",
    "    y_box_moved = cat((y_box_moved, next_frame_box.reshape(1, 28*3, 28*4)), dim=0)\n",
    "   \n",
    "    # show info\n",
    "    plt.imshow(y_moved[frame_old+i], cmap='gray')\n",
    "    plt.imshow(y_box_moved[frame_old+i], cmap='gray', alpha=0.3)\n",
    "    pause(0.1)\n",
    "\n",
    "print(y_moved.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64def4006c78149665c79cf5850ee76c9e416630a0d9e75e41ff194dcaf5fb2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion-MNIST-based simulated production line prediction\n",
    "<font color=#FF0000>Description, TO BE DONE!!</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary packages\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# additional certain short functions\n",
    "from torch import is_tensor\n",
    "from matplotlib.pyplot import pause\n",
    "from random import randint\n",
    "from copy import deepcopy\n",
    "from math import floor, ceil\n",
    "from torch import stack\n",
    "from torch import cat\n",
    "\n",
    "# import custom functions\n",
    "from data_generate import *\n",
    "from data_io import *\n",
    "from CNN import *\n",
    "from FCN import *\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# apply CUDA\n",
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize dataset\n",
    "class ProductLineDataset(Dataset):\n",
    "    def __init__(self, image: torch.Tensor, gt: torch.Tensor):\n",
    "        self.x = image.reshape(len(image), 1, 28*3, 28*4).type(torch.float32)\n",
    "        self.y = gt.type(torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define file names\n",
    "CSV_NAME_TRAIN_02346 = 'train_02346.csv'\n",
    "CSV_NAME_TEST_02346 = 'test_02346.csv'\n",
    "CSV_NAME_TEST_579 = 'test_579.csv'\n",
    "CSV_NAME_TEST_18 = 'test_18.csv'\n",
    "IMAGE_NAME_TRAIN_02346 = 'train_02346'\n",
    "IMAGE_NAME_TEST_02346 = 'test_02346'\n",
    "IMAGE_NAME_TEST_579 = 'test_579'\n",
    "IMAGE_NAME_TEST_18 = 'test_18'\n",
    "\n",
    "# import data\n",
    "gt_train_02346 = gt_import(CSV_NAME_TRAIN_02346)\n",
    "gt_test_02346 = gt_import(CSV_NAME_TEST_02346)\n",
    "gt_test_579 = gt_import(CSV_NAME_TEST_579)\n",
    "gt_test_18 = gt_import(CSV_NAME_TEST_18)\n",
    "image_train_02346 = image_import(gt_train_02346, IMAGE_NAME_TRAIN_02346)/255.\n",
    "image_test_02346 = image_import(gt_test_02346, IMAGE_NAME_TEST_02346)/255.\n",
    "image_test_579 = image_import(gt_test_579, IMAGE_NAME_TEST_579)/255.\n",
    "image_test_18 = image_import(gt_test_18, IMAGE_NAME_TEST_18)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "dataset_train_02346 = ProductLineDataset(image_train_02346, gt_train_02346)\n",
    "dataset_test_02346 = ProductLineDataset(image_test_02346, gt_test_02346)\n",
    "dataset_test_579 = ProductLineDataset(image_test_579, gt_test_579)\n",
    "dataset_test_18 = ProductLineDataset(image_test_18, gt_test_18)\n",
    "\n",
    "# define dataloader\n",
    "dataloader_train_02346 = DataLoader(dataset_train_02346, batch_size=64, shuffle=True)\n",
    "dataloader_test_02346 = DataLoader(dataset_test_02346, batch_size=1, shuffle=True)  # batch_size=1 for test\n",
    "dataloader_test_579 = DataLoader(dataset_test_579, batch_size=1, shuffle=True)\n",
    "dataloader_test_18 = DataLoader(dataset_test_18, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 84, 112])\n",
      "Shape of y:  torch.Size([64])\n",
      "Data type of y:  torch.float32\n",
      "tensor([4., 4., 6., 6., 7., 6., 3., 5., 7., 7., 7., 6., 3., 4., 3., 3., 6., 3.,\n",
      "        6., 3., 7., 4., 7., 4., 6., 4., 5., 4., 5., 5., 3., 3., 3., 3., 4., 5.,\n",
      "        3., 6., 5., 5., 5., 4., 7., 3., 4., 5., 5., 6., 3., 7., 7., 3., 3., 5.,\n",
      "        6., 4., 7., 7., 4., 5., 3., 3., 5., 3.])\n"
     ]
    }
   ],
   "source": [
    "# visualize the shape\n",
    "for X, y in dataloader_train_02346:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape)\n",
    "    print(\"Data type of y: \", y.dtype)\n",
    "    print(y)    # need to transfer [64] to [64, 10] by one-hot coding\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions \n",
    "def train(model, dataloader, loss_fn, optimizer):   # put epoch in main better for loss calculation\n",
    "    # size of dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # set model mode\n",
    "    model.train()\n",
    "    \n",
    "    # train batches per epoch\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # move data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        score = model(X)\n",
    "        loss = loss_fn(score, y/10.)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 40 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test(model, dataloader, loss_fn_train, loss_fn_test):\n",
    "    # size of dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # number of batches\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    # set model mode\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            # move data to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            score = model(X)\n",
    "            test_loss += loss_fn_train(score, y/10.).item()\n",
    "            correct += (y.item()/10. - loss_fn_test(score, y/10.).item()) / (y.item()/10.)    # only for batch_size=1\n",
    "    \n",
    "    # calculate the average loss and accuracy\n",
    "    test_loss /= num_batches\n",
    "    correct /= num_batches\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN(\n",
      "  (fc1): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=9408, out_features=4096, bias=True)\n",
      "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (fc3): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (fc4): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (fc5): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (fc6): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=8, bias=True)\n",
      "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_channel = (28*3)*(28*4)\n",
    "node_1 = 4096\n",
    "node_2 = 1024\n",
    "node_3 = 1024\n",
    "node_4 = 256\n",
    "node_5 = 64\n",
    "node_6 = 8\n",
    "out_channel = 1\n",
    "\n",
    "FCN_model = FCN(in_channel, node_1, node_2, node_3, node_4, \\\n",
    "    node_5, node_6, out_channel).to(device=device)\n",
    "print(FCN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=2240, out_features=1024, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc3): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (fc4): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_channel = 1\n",
    "channel_1 = 4\n",
    "channel_2 = 8\n",
    "channel_3 = 16\n",
    "node_1 = 1024\n",
    "node_2 = 1024\n",
    "node_3 = 256\n",
    "node_4 = 64\n",
    "out_channel = 1\n",
    "\n",
    "CNN_model = CNN(in_channel, channel_1, channel_2, channel_3, \\\n",
    "    node_1, node_2, node_3, node_4, out_channel).to(device=device)\n",
    "print(CNN_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup and train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# define lose function\n",
    "loss_fn_train = nn.MSELoss()\n",
    "loss_fn_test = nn.L1Loss()\n",
    "\n",
    "# define optimizer\n",
    "optimizer_FCN = torch.optim.Adam(FCN_model.parameters(), lr=learning_rate)\n",
    "optimizer_CNN = torch.optim.Adam(CNN_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.231278  [    0/10415]\n",
      "loss: 0.031181  [ 2560/10415]\n",
      "loss: 0.025409  [ 5120/10415]\n",
      "loss: 0.023247  [ 7680/10415]\n",
      "loss: 0.020751  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.021580 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.021952  [    0/10415]\n",
      "loss: 0.022875  [ 2560/10415]\n",
      "loss: 0.016569  [ 5120/10415]\n",
      "loss: 0.018011  [ 7680/10415]\n",
      "loss: 0.022932  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.021443 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.018424  [    0/10415]\n",
      "loss: 0.019572  [ 2560/10415]\n",
      "loss: 0.025865  [ 5120/10415]\n",
      "loss: 0.017935  [ 7680/10415]\n",
      "loss: 0.021914  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.021398 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.016854  [    0/10415]\n",
      "loss: 0.021165  [ 2560/10415]\n",
      "loss: 0.022858  [ 5120/10415]\n",
      "loss: 0.024479  [ 7680/10415]\n",
      "loss: 0.018903  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.021340 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.022007  [    0/10415]\n",
      "loss: 0.023393  [ 2560/10415]\n",
      "loss: 0.019249  [ 5120/10415]\n",
      "loss: 0.019449  [ 7680/10415]\n",
      "loss: 0.020680  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.020939 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.018695  [    0/10415]\n",
      "loss: 0.019621  [ 2560/10415]\n",
      "loss: 0.021812  [ 5120/10415]\n",
      "loss: 0.020960  [ 7680/10415]\n",
      "loss: 0.021291  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.021836 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.016346  [    0/10415]\n",
      "loss: 0.019905  [ 2560/10415]\n",
      "loss: 0.020068  [ 5120/10415]\n",
      "loss: 0.026316  [ 7680/10415]\n",
      "loss: 0.019898  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.021170 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.020686  [    0/10415]\n",
      "loss: 0.019914  [ 2560/10415]\n",
      "loss: 0.019376  [ 5120/10415]\n",
      "loss: 0.021177  [ 7680/10415]\n",
      "loss: 0.019891  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.021586 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.025216  [    0/10415]\n",
      "loss: 0.020509  [ 2560/10415]\n",
      "loss: 0.021003  [ 5120/10415]\n",
      "loss: 0.021445  [ 7680/10415]\n",
      "loss: 0.022449  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.021276 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.017978  [    0/10415]\n",
      "loss: 0.016535  [ 2560/10415]\n",
      "loss: 0.022233  [ 5120/10415]\n",
      "loss: 0.022192  [ 7680/10415]\n",
      "loss: 0.019931  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.021171 \n",
      "\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "# set epoch\n",
    "epoch = 10\n",
    "\n",
    "# start training\n",
    "for t in range(epoch):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(FCN_model, dataloader_train_02346, loss_fn_train, optimizer_FCN)\n",
    "    test(FCN_model, dataloader_test_02346, loss_fn_train, loss_fn_test)\n",
    "print(\"Done!!\")\n",
    "\n",
    "# model saving\n",
    "torch.save(FCN_model.state_dict(), \"FCN.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.123665  [    0/10415]\n",
      "loss: 0.030165  [ 2560/10415]\n",
      "loss: 0.027246  [ 5120/10415]\n",
      "loss: 0.021267  [ 7680/10415]\n",
      "loss: 0.023675  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.028393 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.023180  [    0/10415]\n",
      "loss: 0.022445  [ 2560/10415]\n",
      "loss: 0.020435  [ 5120/10415]\n",
      "loss: 0.021895  [ 7680/10415]\n",
      "loss: 0.021527  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.030693 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.018587  [    0/10415]\n",
      "loss: 0.022913  [ 2560/10415]\n",
      "loss: 0.023693  [ 5120/10415]\n",
      "loss: 0.024786  [ 7680/10415]\n",
      "loss: 0.021452  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.027758 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.018888  [    0/10415]\n",
      "loss: 0.023242  [ 2560/10415]\n",
      "loss: 0.025638  [ 5120/10415]\n",
      "loss: 0.015348  [ 7680/10415]\n",
      "loss: 0.024268  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.022699 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.023486  [    0/10415]\n",
      "loss: 0.022828  [ 2560/10415]\n",
      "loss: 0.021007  [ 5120/10415]\n",
      "loss: 0.020077  [ 7680/10415]\n",
      "loss: 0.020570  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.021046 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.021160  [    0/10415]\n",
      "loss: 0.020293  [ 2560/10415]\n",
      "loss: 0.019168  [ 5120/10415]\n",
      "loss: 0.015148  [ 7680/10415]\n",
      "loss: 0.016743  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.020667 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.018774  [    0/10415]\n",
      "loss: 0.019568  [ 2560/10415]\n",
      "loss: 0.018939  [ 5120/10415]\n",
      "loss: 0.022209  [ 7680/10415]\n",
      "loss: 0.019981  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.021138 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.021140  [    0/10415]\n",
      "loss: 0.015772  [ 2560/10415]\n",
      "loss: 0.019270  [ 5120/10415]\n",
      "loss: 0.016788  [ 7680/10415]\n",
      "loss: 0.016647  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.020943 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.020122  [    0/10415]\n",
      "loss: 0.020749  [ 2560/10415]\n",
      "loss: 0.019418  [ 5120/10415]\n",
      "loss: 0.020421  [ 7680/10415]\n",
      "loss: 0.019471  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.020973 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.024196  [    0/10415]\n",
      "loss: 0.021218  [ 2560/10415]\n",
      "loss: 0.020462  [ 5120/10415]\n",
      "loss: 0.021029  [ 7680/10415]\n",
      "loss: 0.019468  [10240/10415]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.020757 \n",
      "\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "# set epoch\n",
    "epoch = 10\n",
    "\n",
    "# start training\n",
    "for t in range(epoch):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(CNN_model, dataloader_train_02346, loss_fn_train, optimizer_CNN)\n",
    "    test(CNN_model, dataloader_test_02346, loss_fn_train, loss_fn_test)\n",
    "print(\"Done!!\")\n",
    "\n",
    "# model saving\n",
    "torch.save(CNN_model.state_dict(), \"CNN.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#FF0000>Visualization reference (non-used yet) <font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single bounding box testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box(col, row, box_x, box_y):    # position + length / width (visualization usage)\n",
    "    view = torch.zeros([28*3, 28*4], dtype=torch.float32)\n",
    "    # set the box, outside the target with one pixel\n",
    "    view[row-box_y:row+1, col-box_x] = 1\n",
    "    view[row-box_y:row+1, col] = 1\n",
    "    view[row-box_y, col-box_x:col+1] = 1\n",
    "    view[row, col-box_x:col+1] = 1\n",
    "    return view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import pause\n",
    "from random import randint\n",
    "from copy import deepcopy\n",
    "\n",
    "rand_x = randint(14, 27)\n",
    "rand_y = randint(27, 28*3-1)\n",
    "print(\"new start position [x, y] = [\", rand_x,\",\", rand_y, \"]\")\n",
    "\n",
    "rand_start = deepcopy(aug_sample)\n",
    "box_origin = box(27, 21, 27, 15)    # array for visualization, the only manual input part\n",
    "box_sample = deepcopy(box_origin)\n",
    "\n",
    "plt.imshow(rand_start, cmap='gray')\n",
    "plt.imshow(box_origin, cmap='gray', alpha=0.3)\n",
    "pause(0.1)\n",
    "\n",
    "# initial movement\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        rand_start[rand_y-i][rand_x-j] = rand_start[27-i][27-j]\n",
    "\n",
    "for i in range(29):\n",
    "    for j in range(29):\n",
    "        box_origin[rand_y-i+1][rand_x-j+1] = box_origin[28-i][28-j]\n",
    "\n",
    "# clean other part\n",
    "rand_start[:rand_y-28+1, :] = 0\n",
    "rand_start[:, rand_x+1:rand_x+28+1] = 0\n",
    "box_origin[:rand_y-28, :] = 0       # 1-pixel cleaning region difference\n",
    "box_origin[:, rand_x+1:rand_x+28+1] = 0\n",
    "\n",
    "plt.imshow(rand_start, cmap='gray')\n",
    "plt.imshow(box_origin, cmap='gray', alpha=0.3)\n",
    "pause(0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sequential bounding box visualization and random position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil\n",
    "from torch import cat\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import pause\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequential box preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "stride = 5\n",
    "first_frame = deepcopy(box_sample)\n",
    "next_frame = deepcopy(box_sample)\n",
    "y_box = deepcopy(box_sample)\n",
    "\n",
    "# show info\n",
    "print(y_box.size())\n",
    "plt.imshow(y_box, cmap='gray')\n",
    "pause(0.1)\n",
    "\n",
    "for i in range(floor((112-28)/stride)):\n",
    "   # moving part (1-dim only)\n",
    "   for j in range(30):  # bigger range to cover bounding box\n",
    "      next_frame[:, 30+stride*(i+1)-(j+1)] = next_frame[:, 30+stride*i-(j+1)]\n",
    "   next_frame[:, :stride*(i+1)] = 0  # clean other area\n",
    "   \n",
    "   # sequencing part\n",
    "   if i == 0:\n",
    "      y_box = stack((first_frame, next_frame)) \n",
    "   else:\n",
    "      y_box = cat((y_box, next_frame.reshape(1, 28*3, 28*4)), dim=0)\n",
    "      \n",
    "   # # show info\n",
    "   # print(y_box.size())\n",
    "   # plt.imshow(y_box[i+1], cmap='gray')\n",
    "   # pause(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parallel moving and concat last frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential data preparation\n",
    "y_box_moved = deepcopy(y_box)\n",
    "y_moved = deepcopy(y)\n",
    "rand_x = randint(14, 27)\n",
    "rand_y = randint(27, 28*3-1)\n",
    "print(\"new start position [x, y] = [\", rand_x,\",\", rand_y, \"]\")\n",
    "\n",
    "# # visualization for no parallel movement\n",
    "# for i in range(len(y_box_moved)):\n",
    "#     plt.imshow(y_moved[i], cmap='gray')\n",
    "#     plt.imshow(y_box_moved[i], cmap='gray', alpha=0.3)\n",
    "#     pause(0.1)\n",
    "\n",
    "# all frames move left parellel\n",
    "for i in range(floor((112-28)/stride)+1): \n",
    "    # moving items\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            y_moved[i][rand_y-j][rand_x+stride*i-k] = y_moved[i][27-j][27+stride*i-k]\n",
    "    # moving box\n",
    "    for j in range(29):\n",
    "        for k in range(29):\n",
    "            y_box_moved[i][rand_y-j+1][rand_x+stride*i-k+1] = y_box_moved[i][28-j][28+stride*i-k]\n",
    "          \n",
    "    # clean other area\n",
    "    y_moved[i][:rand_y-28+1, :] = 0\n",
    "    y_moved[i][:, rand_x+stride*i+1:] = 0\n",
    "    y_box_moved[i][:rand_y-28+1, :] = 0\n",
    "    y_box_moved[i][:, rand_x+stride*i+1:] = 0\n",
    "   \n",
    "    # show info\n",
    "    plt.imshow(y_moved[i], cmap='gray')\n",
    "    plt.imshow(y_box_moved[i], cmap='gray', alpha=0.3)\n",
    "    pause(0.1)\n",
    "\n",
    "# initialization\n",
    "frame_old = len(y_moved)   # number of old frames\n",
    "next_frame = deepcopy(y_moved[frame_old-1])\n",
    "next_frame_box = deepcopy(y_box_moved[frame_old-1])\n",
    "\n",
    "# last frame moves right and cat\n",
    "for i in range(ceil((28-rand_x)/stride)+1):\n",
    "    # move next frame\n",
    "    for j in range(28):\n",
    "        if rand_x+stride*(frame_old+i)-j < 112:\n",
    "           next_frame[:, rand_x+stride*(frame_old+i)-j] = next_frame[:, rand_x+stride*(frame_old+i-1)-j]\n",
    "    for j in range(29):\n",
    "        if rand_x+stride*(frame_old+i)-j+1 < 112:\n",
    "           next_frame_box[:, rand_x+stride*(frame_old+i)-j+1] = next_frame_box[:, rand_x+stride*(frame_old+i-1)-j+1]\n",
    "    # clean and cat\n",
    "    next_frame[:, :rand_x+stride*(frame_old+i)-28+1] = 0\n",
    "    y_moved = cat((y_moved, next_frame.reshape(1, 28*3, 28*4)), dim=0)\n",
    "    next_frame_box[:, :rand_x+stride*(frame_old+i)-28+1] = 0\n",
    "    y_box_moved = cat((y_box_moved, next_frame_box.reshape(1, 28*3, 28*4)), dim=0)\n",
    "   \n",
    "    # show info\n",
    "    plt.imshow(y_moved[frame_old+i], cmap='gray')\n",
    "    plt.imshow(y_box_moved[frame_old+i], cmap='gray', alpha=0.3)\n",
    "    pause(0.1)\n",
    "\n",
    "print(y_moved.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64def4006c78149665c79cf5850ee76c9e416630a0d9e75e41ff194dcaf5fb2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

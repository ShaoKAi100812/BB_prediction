{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion-MNIST dataset classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shuang07\\.conda\\envs\\auto_labeling\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# necessary packages\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# additional packages\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth =  Ankle boot\n",
      "Dataset size =  60000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get training dataset\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# get testing dataset\n",
    "testing_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# class names\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "# print random item to visualize\n",
    "rand = random.randint(0, 59999)\n",
    "img = training_data.__getitem__(rand)[0].reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')\n",
    "print(\"ground truth = \", classes[training_data.__getitem__(rand)[1]])\n",
    "\n",
    "# print dataset size \n",
    "size = len(training_data)\n",
    "print(\"Dataset size = \", size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64])\n",
      "Data type of y:  torch.int64\n",
      "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
      "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
      "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n"
     ]
    }
   ],
   "source": [
    "# setup batchsize\n",
    "batch_size = 64\n",
    "\n",
    "# create dataloader (iterable)\n",
    "training_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "testing_dataloader = DataLoader(testing_data, batch_size=batch_size)\n",
    "\n",
    "# visualize the shape\n",
    "for X, y in testing_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape)\n",
    "    print(\"Data type of y: \", y.dtype)\n",
    "    print(y)    # need to transfer [64] to [64, 10] by one-hot coding\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "# testing block\n",
    "print(len(training_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cpu\n"
     ]
    }
   ],
   "source": [
    "# apply CUDA\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "print(\"device = \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define basic model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        score = self.linear(x)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "basic_model = NeuralNetwork().to(device=device)\n",
    "print(basic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# define lose function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(basic_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions \n",
    "def train(model, dataloader, loss_fn, optimizer):   # put epoch in main better for loss calculation\n",
    "    # size of dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # set model mode\n",
    "    model.train()\n",
    "    \n",
    "    # train batches per epoch\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # move data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        score = model(X)\n",
    "        loss = loss_fn(score, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test(model, dataloader, loss_fn):\n",
    "    # size of dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # number of batches\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    # set model mode\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            # move data to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            score = model(X)\n",
    "            test_loss += loss_fn(score, y).item()\n",
    "            correct += (score.argmax(1)==y).type(torch.float).sum().item()\n",
    "    \n",
    "    # calculate the average loss and accuracy\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.290245  [    0/60000]\n",
      "loss: 2.266938  [25600/60000]\n",
      "loss: 2.214560  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 22.1%, Avg loss: 2.194719 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.185401  [    0/60000]\n",
      "loss: 2.128687  [25600/60000]\n",
      "loss: 2.038170  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 1.991113 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.997490  [    0/60000]\n",
      "loss: 1.843697  [25600/60000]\n",
      "loss: 1.733488  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 1.659204 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.699053  [    0/60000]\n",
      "loss: 1.486567  [25600/60000]\n",
      "loss: 1.436218  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 1.362513 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.430428  [    0/60000]\n",
      "loss: 1.234457  [25600/60000]\n",
      "loss: 1.234468  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 1.169414 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.239217  [    0/60000]\n",
      "loss: 1.068885  [25600/60000]\n",
      "loss: 1.103382  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.044736 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.107204  [    0/60000]\n",
      "loss: 0.961680  [25600/60000]\n",
      "loss: 1.012815  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 0.960156 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.011391  [    0/60000]\n",
      "loss: 0.889975  [25600/60000]\n",
      "loss: 0.947235  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.899881 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.938618  [    0/60000]\n",
      "loss: 0.839611  [25600/60000]\n",
      "loss: 0.898273  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.855059 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.881616  [    0/60000]\n",
      "loss: 0.802463  [25600/60000]\n",
      "loss: 0.860462  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.820345 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.835191  [    0/60000]\n",
      "loss: 0.773694  [25600/60000]\n",
      "loss: 0.830702  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.792381 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.795977  [    0/60000]\n",
      "loss: 0.750221  [25600/60000]\n",
      "loss: 0.806365  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.769002 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.761953  [    0/60000]\n",
      "loss: 0.730501  [25600/60000]\n",
      "loss: 0.785748  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.748779 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.732075  [    0/60000]\n",
      "loss: 0.713467  [25600/60000]\n",
      "loss: 0.767722  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.730781 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.705305  [    0/60000]\n",
      "loss: 0.698415  [25600/60000]\n",
      "loss: 0.751681  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.714416 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.681009  [    0/60000]\n",
      "loss: 0.684941  [25600/60000]\n",
      "loss: 0.737305  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.699314 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.658750  [    0/60000]\n",
      "loss: 0.672846  [25600/60000]\n",
      "loss: 0.724304  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.685243 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.638240  [    0/60000]\n",
      "loss: 0.661935  [25600/60000]\n",
      "loss: 0.712438  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.672073 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.619326  [    0/60000]\n",
      "loss: 0.652055  [25600/60000]\n",
      "loss: 0.701599  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.659735 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.601884  [    0/60000]\n",
      "loss: 0.643108  [25600/60000]\n",
      "loss: 0.691765  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.648188 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.585810  [    0/60000]\n",
      "loss: 0.635092  [25600/60000]\n",
      "loss: 0.682922  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.637387 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.570965  [    0/60000]\n",
      "loss: 0.627872  [25600/60000]\n",
      "loss: 0.674998  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.627297 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.557215  [    0/60000]\n",
      "loss: 0.621235  [25600/60000]\n",
      "loss: 0.668088  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.617902 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.544349  [    0/60000]\n",
      "loss: 0.615156  [25600/60000]\n",
      "loss: 0.662084  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.609158 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.532345  [    0/60000]\n",
      "loss: 0.609519  [25600/60000]\n",
      "loss: 0.656913  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.601027 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.521076  [    0/60000]\n",
      "loss: 0.604188  [25600/60000]\n",
      "loss: 0.652554  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.593462 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.510488  [    0/60000]\n",
      "loss: 0.599050  [25600/60000]\n",
      "loss: 0.648850  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.586415 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.500506  [    0/60000]\n",
      "loss: 0.594007  [25600/60000]\n",
      "loss: 0.645689  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.579842 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.491029  [    0/60000]\n",
      "loss: 0.588947  [25600/60000]\n",
      "loss: 0.642999  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.573698 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.482090  [    0/60000]\n",
      "loss: 0.584041  [25600/60000]\n",
      "loss: 0.640679  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.567939 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.473617  [    0/60000]\n",
      "loss: 0.579184  [25600/60000]\n",
      "loss: 0.638701  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.562545 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.465548  [    0/60000]\n",
      "loss: 0.574353  [25600/60000]\n",
      "loss: 0.636912  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.557482 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.457864  [    0/60000]\n",
      "loss: 0.569533  [25600/60000]\n",
      "loss: 0.635305  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.552720 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.450544  [    0/60000]\n",
      "loss: 0.564704  [25600/60000]\n",
      "loss: 0.633826  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.548238 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.443558  [    0/60000]\n",
      "loss: 0.559908  [25600/60000]\n",
      "loss: 0.632457  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.544009 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.436902  [    0/60000]\n",
      "loss: 0.555148  [25600/60000]\n",
      "loss: 0.631132  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.540015 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.430497  [    0/60000]\n",
      "loss: 0.550389  [25600/60000]\n",
      "loss: 0.629837  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.536239 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.424415  [    0/60000]\n",
      "loss: 0.545642  [25600/60000]\n",
      "loss: 0.628563  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.532663 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.418595  [    0/60000]\n",
      "loss: 0.540977  [25600/60000]\n",
      "loss: 0.627295  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.529272 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.413004  [    0/60000]\n",
      "loss: 0.536314  [25600/60000]\n",
      "loss: 0.625942  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.526053 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.407625  [    0/60000]\n",
      "loss: 0.531742  [25600/60000]\n",
      "loss: 0.624567  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.522995 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.402428  [    0/60000]\n",
      "loss: 0.527290  [25600/60000]\n",
      "loss: 0.623116  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.520090 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.397426  [    0/60000]\n",
      "loss: 0.522896  [25600/60000]\n",
      "loss: 0.621582  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.517325 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.392583  [    0/60000]\n",
      "loss: 0.518596  [25600/60000]\n",
      "loss: 0.620011  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.514692 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.387895  [    0/60000]\n",
      "loss: 0.514401  [25600/60000]\n",
      "loss: 0.618337  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.512177 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.383371  [    0/60000]\n",
      "loss: 0.510302  [25600/60000]\n",
      "loss: 0.616589  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.509773 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.379015  [    0/60000]\n",
      "loss: 0.506335  [25600/60000]\n",
      "loss: 0.614866  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.507473 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.374785  [    0/60000]\n",
      "loss: 0.502473  [25600/60000]\n",
      "loss: 0.613136  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.505272 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.370688  [    0/60000]\n",
      "loss: 0.498782  [25600/60000]\n",
      "loss: 0.611374  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.503158 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.366751  [    0/60000]\n",
      "loss: 0.495197  [25600/60000]\n",
      "loss: 0.609540  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.501130 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.362929  [    0/60000]\n",
      "loss: 0.491707  [25600/60000]\n",
      "loss: 0.607619  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.499179 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.359229  [    0/60000]\n",
      "loss: 0.488373  [25600/60000]\n",
      "loss: 0.605744  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.497306 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.355626  [    0/60000]\n",
      "loss: 0.485055  [25600/60000]\n",
      "loss: 0.603862  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.495503 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.352099  [    0/60000]\n",
      "loss: 0.481855  [25600/60000]\n",
      "loss: 0.601958  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.493766 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.348670  [    0/60000]\n",
      "loss: 0.478762  [25600/60000]\n",
      "loss: 0.600033  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.492085 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.345311  [    0/60000]\n",
      "loss: 0.475777  [25600/60000]\n",
      "loss: 0.598126  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.490464 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.342055  [    0/60000]\n",
      "loss: 0.472900  [25600/60000]\n",
      "loss: 0.596222  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.488897 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.338885  [    0/60000]\n",
      "loss: 0.470136  [25600/60000]\n",
      "loss: 0.594266  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.487376 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.335814  [    0/60000]\n",
      "loss: 0.467434  [25600/60000]\n",
      "loss: 0.592263  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.485899 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.332822  [    0/60000]\n",
      "loss: 0.464807  [25600/60000]\n",
      "loss: 0.590377  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.484471 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.329892  [    0/60000]\n",
      "loss: 0.462309  [25600/60000]\n",
      "loss: 0.588552  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.483087 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.327070  [    0/60000]\n",
      "loss: 0.459863  [25600/60000]\n",
      "loss: 0.586817  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.481741 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.324292  [    0/60000]\n",
      "loss: 0.457448  [25600/60000]\n",
      "loss: 0.585121  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.480434 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.321585  [    0/60000]\n",
      "loss: 0.455082  [25600/60000]\n",
      "loss: 0.583403  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.479161 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.318970  [    0/60000]\n",
      "loss: 0.452802  [25600/60000]\n",
      "loss: 0.581634  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.477923 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.316443  [    0/60000]\n",
      "loss: 0.450593  [25600/60000]\n",
      "loss: 0.579896  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.476719 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.314008  [    0/60000]\n",
      "loss: 0.448411  [25600/60000]\n",
      "loss: 0.578158  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.475541 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.311613  [    0/60000]\n",
      "loss: 0.446280  [25600/60000]\n",
      "loss: 0.576488  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.474394 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.309267  [    0/60000]\n",
      "loss: 0.444177  [25600/60000]\n",
      "loss: 0.574878  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.473276 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.306998  [    0/60000]\n",
      "loss: 0.442139  [25600/60000]\n",
      "loss: 0.573216  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.472181 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.304809  [    0/60000]\n",
      "loss: 0.440152  [25600/60000]\n",
      "loss: 0.571574  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.471108 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.302669  [    0/60000]\n",
      "loss: 0.438221  [25600/60000]\n",
      "loss: 0.569922  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.470061 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.300578  [    0/60000]\n",
      "loss: 0.436313  [25600/60000]\n",
      "loss: 0.568326  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.469041 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.298563  [    0/60000]\n",
      "loss: 0.434465  [25600/60000]\n",
      "loss: 0.566784  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.468036 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.296620  [    0/60000]\n",
      "loss: 0.432621  [25600/60000]\n",
      "loss: 0.565209  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.467056 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.294719  [    0/60000]\n",
      "loss: 0.430808  [25600/60000]\n",
      "loss: 0.563647  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.466087 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.292886  [    0/60000]\n",
      "loss: 0.429019  [25600/60000]\n",
      "loss: 0.562034  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.465127 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.291078  [    0/60000]\n",
      "loss: 0.427217  [25600/60000]\n",
      "loss: 0.560453  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.464192 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.289314  [    0/60000]\n",
      "loss: 0.425441  [25600/60000]\n",
      "loss: 0.558903  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.463276 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.287627  [    0/60000]\n",
      "loss: 0.423753  [25600/60000]\n",
      "loss: 0.557341  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.462372 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.285972  [    0/60000]\n",
      "loss: 0.422030  [25600/60000]\n",
      "loss: 0.555837  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.461487 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.284375  [    0/60000]\n",
      "loss: 0.420375  [25600/60000]\n",
      "loss: 0.554377  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.460618 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.282845  [    0/60000]\n",
      "loss: 0.418699  [25600/60000]\n",
      "loss: 0.552947  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.459764 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.281355  [    0/60000]\n",
      "loss: 0.417130  [25600/60000]\n",
      "loss: 0.551413  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.458926 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.279963  [    0/60000]\n",
      "loss: 0.415539  [25600/60000]\n",
      "loss: 0.549959  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.458093 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.278608  [    0/60000]\n",
      "loss: 0.413931  [25600/60000]\n",
      "loss: 0.548467  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.457271 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.277267  [    0/60000]\n",
      "loss: 0.412376  [25600/60000]\n",
      "loss: 0.547016  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.456464 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.275964  [    0/60000]\n",
      "loss: 0.410811  [25600/60000]\n",
      "loss: 0.545535  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.455670 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.274667  [    0/60000]\n",
      "loss: 0.409267  [25600/60000]\n",
      "loss: 0.544093  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.454888 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.273431  [    0/60000]\n",
      "loss: 0.407814  [25600/60000]\n",
      "loss: 0.542684  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.454115 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.272214  [    0/60000]\n",
      "loss: 0.406388  [25600/60000]\n",
      "loss: 0.541241  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.453352 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.271076  [    0/60000]\n",
      "loss: 0.404998  [25600/60000]\n",
      "loss: 0.539757  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.452601 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.269964  [    0/60000]\n",
      "loss: 0.403629  [25600/60000]\n",
      "loss: 0.538307  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.451858 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.268886  [    0/60000]\n",
      "loss: 0.402218  [25600/60000]\n",
      "loss: 0.536968  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.451123 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.267839  [    0/60000]\n",
      "loss: 0.400826  [25600/60000]\n",
      "loss: 0.535619  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.450398 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.266786  [    0/60000]\n",
      "loss: 0.399502  [25600/60000]\n",
      "loss: 0.534287  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.449681 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.265716  [    0/60000]\n",
      "loss: 0.398249  [25600/60000]\n",
      "loss: 0.532929  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.448970 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.264731  [    0/60000]\n",
      "loss: 0.396959  [25600/60000]\n",
      "loss: 0.531619  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.448260 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.263744  [    0/60000]\n",
      "loss: 0.395634  [25600/60000]\n",
      "loss: 0.530299  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.447559 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.262789  [    0/60000]\n",
      "loss: 0.394309  [25600/60000]\n",
      "loss: 0.528937  [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.446854 \n",
      "\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "# set epoch\n",
    "epoch = 100\n",
    "\n",
    "# start training\n",
    "for t in range(epoch):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(basic_model, training_dataloader, loss_fn, optimizer)\n",
    "    test(basic_model, testing_dataloader, loss_fn)\n",
    "print(\"Done!!\")\n",
    "\n",
    "# model saving\n",
    "torch.save(basic_model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model_trained = NeuralNetwork()\n",
    "model_trained.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction：\"Shirt\" / ground truth：\"Shirt\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f0f6b2edf0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class names\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "# get random data from testing dataset\n",
    "rand = random.randint(0, 9999)\n",
    "x, y = testing_data[rand][0], testing_data[rand][1]\n",
    "\n",
    "# switch mode\n",
    "model_trained.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model_trained(x)\n",
    "\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'prediction：\"{predicted}\" / ground truth：\"{actual}\"')\n",
    "    \n",
    "# print random item to visualize\n",
    "img = testing_data.__getitem__(rand)[0].reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('auto_labeling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec129e0590d45a22483b850cd1c473456f2c02a48b73be1599d608a53736fee7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
